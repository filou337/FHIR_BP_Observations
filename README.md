````markdown
# ğŸ©º FHIR Blood Pressure Monitoring â€” Kafka â€¢ Elasticsearch â€¢ Kibana (+ ML optionnel)

Pipeline **temps rÃ©el** de surveillance de **pression artÃ©rielle** au format **FHIR (JSON)** : gÃ©nÃ©ration de donnÃ©es (patients/praticiens), ingestion Kafka, analyse & routage, stockage ciblÃ© dans Elasticsearch, visualisation Kibana â€” avec une **brique Machine Learning optionnelle** pour complÃ©ter les rÃ¨gles Ã  seuils.

---

## âœ¨ FonctionnalitÃ©s

- âœ… GÃ©nÃ©ration dâ€™observations **FHIR Blood Pressure** en JSON (via `Faker`)
- âœ… Publication streaming dans **Kafka**
- âœ… Consumer Python : **validation**, **extraction**, **rÃ¨gles cliniques**
- âœ… Routage :
  - **NORMAL** â†’ archivage **local** (JSONL)
  - **ANORMAL** â†’ indexation **Elasticsearch** + visualisation **Kibana**
- âœ… 4 cas dâ€™alerte â€œnot normalâ€ exposÃ©s dans Kibana (dashboard/table)
- ğŸ§  **Option ML** : modÃ¨le supervisÃ© entraÃ®nÃ© sur les rÃ¨gles â†’ prÃ©diction temps rÃ©el + score/proba de risque

---

## ğŸ§± Architecture

```text
[ fhir_data_generator.py ]  -> gÃ©nÃ¨re Observation FHIR (JSON)
          |
          v
[ fhir_producer.py ]  -> envoie vers Kafka (topic raw)
          |
          v
[ fhir_consumer.py ]  -> lit Kafka, valide, applique rÃ¨gles
      |                         |
      | NORMAL                  | NOT NORMAL
      v                         v
archives/*.jsonl        Elasticsearch (index)
                               |
                               v
                            Kibana
````

---

## ğŸ“¦ Stack

* **Python 3.11+**
* **Kafka** (Docker)
* **Elasticsearch + Kibana** (Docker)
* Libs principales : `faker`, `confluent-kafka`, `elasticsearch`, `numpy`, `pandas`
* (Option ML) `scikit-learn`

---

## ğŸ“ Structure du repo

```text
.
â”œâ”€â”€ Docker-compose.yml
â”œâ”€â”€ Requierement.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ fhir_data_generator.py
â”œâ”€â”€ fhir_producer.py
â”œâ”€â”€ fhir_consumer.py
â”œâ”€â”€ ml_feature_extraction.py
â”œâ”€â”€ ml_training.py
â””â”€â”€ archives/
```

---

## ğŸ“„ Format FHIR (minimal conservÃ©)

RÃ©fÃ©rence dâ€™exemple (Observation Blood Pressure) :

* [https://build.fhir.org/observation-example-bloodpressure.json.html](https://build.fhir.org/observation-example-bloodpressure.json.html)

Champs conservÃ©s / exploitÃ©s :

* **Patient**
* **Practitioner**
* **Systolic**
* **Diastolic**

GÃ©nÃ©ration :

* FrÃ©quence : toutes les **1s** ou **5s**
* Population : **5 patients** et **1â€“2 praticiens**

---

## ğŸ§µ Topics Kafka (recommandation)

* **EntrÃ©e**

  * `fhir-observations-raw` : Observations FHIR brutes (Blood Pressure)

* **Sorties**

  * `fhir-observations-validated` : Observation validÃ©e / enrichie
  * `blood-pressure-alerts` : Alertes (uniquement anomalies)
  * `error-messages` : Parsing/validation errors
  * `monitoring-metrics` : Petites mÃ©triques (dÃ©bit, volumes)

---

## âœ… RÃ¨gles dâ€™analyse & routage

Ã€ chaque observation consommÃ©e :

1. Validation minimale (message bien formÃ©, champs attendus prÃ©sents)
2. Extraction des valeurs **systolic** et **diastolic**
3. Classification :

* **Si NORMAL**

  * Stockage **local** dans `archives/` au format **JSONL**

* **Si NOT NORMAL**

  * CrÃ©ation dâ€™une alerte (catÃ©gorie / niveau)
  * Indexation dans **Elasticsearch**
  * Exposition dans **Kibana** via un tableau de bord

> Les **4 cas dâ€™alerte** â€œnot normal blood pressureâ€ sont stockÃ©s dans Elasticsearch et visualisÃ©s dans Kibana.

---

## ğŸš€ Quickstart

### 1) Lancer lâ€™infrastructure (Kafka + Elasticsearch + Kibana)

```bash
docker compose -f Docker-compose.yml up -d
```

VÃ©rifier lâ€™Ã©tat :

```bash
docker compose -f Docker-compose.yml ps
```

### 2) Installer les dÃ©pendances Python

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# macOS/Linux
source .venv/bin/activate

pip install -r Requierement.txt
```

### 3) DÃ©marrer le pipeline temps rÃ©el

**Terminal A â€” Consumer (analyse + routage)**

```bash
python fhir_consumer.py
```

**Terminal B â€” Producer (gÃ©nÃ©ration + push Kafka)**

```bash
python fhir_producer.py
```

---

## ğŸŒ Interfaces

* **Kibana** : [http://localhost:5601](http://localhost:5601)
* **Elasticsearch** : [http://localhost:9200](http://localhost:9200)
* **Kafka UI** (si prÃ©sent) : [http://localhost:8080](http://localhost:8080)

---

## ğŸ§  Section optionnelle â€” Machine Learning

Pour ceux qui souhaitent aller plus loin : intÃ©grer une dimension IA via un modÃ¨le supervisÃ© (ex. **rÃ©gression logistique** ou classification).

Principe :

* Le modÃ¨le est entraÃ®nÃ© Ã  partir des donnÃ©es de pression artÃ©rielle en utilisant les **seuils cliniques** comme labels (normal / anormal ou multi-classes).
* Une fois entraÃ®nÃ©, il est **chargÃ© dans le consumer Kafka** pour produire une **prÃ©diction temps rÃ©el** sur chaque nouvelle mesure.
* Le modÃ¨le complÃ¨te les rÃ¨gles basÃ©es sur les seuils en fournissant une **estimation probabiliste du risque**, rendant le systÃ¨me plus **rÃ©aliste**, **prÃ©dictif** et **adaptable**.

### Workflow conseillÃ©

1. Extraction de features (ex : systolic, diastolic, dÃ©rivÃ©s, tendances)
2. EntraÃ®nement du modÃ¨le
3. Sauvegarde dans `ml_models/`
4. Chargement dans `fhir_consumer.py` pour annoter les observations :

   * `ml_prediction`
   * `ml_proba` (ou `risk_score`)

### Lancer lâ€™entraÃ®nement (exemple)

```bash
python ml_training.py
```

---

## ğŸ“Š Kibana â€” idÃ©es de dashboard

* Table : derniÃ¨res alertes (patient, praticien, systolic, diastolic, catÃ©gorie)
* SÃ©rie temporelle : Ã©volution systolic/diastolic
* Filtres : catÃ©gorie, niveau, patient, praticien
* Compteurs : volumes NORMAL vs ANORMAL

---

## ğŸ§¯ Troubleshooting

### Voir les logs Docker

```bash
docker compose -f Docker-compose.yml logs -f
```

### VÃ©rifier ports libres

* `9092` (Kafka)
* `9200` (Elasticsearch)
* `5601` (Kibana)
* `8080` (Kafka UI si activÃ©)

### Kibana â€œnot readyâ€

Attendre que Elasticsearch soit â€œhealthyâ€ (souvent 1â€“2 minutes aprÃ¨s `up -d`).

---

## ğŸ‘¤ Auteurs

* **Philippe ROUMBO**
* **Salma ELABSODI**

```
