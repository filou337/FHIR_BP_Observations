"""
ML PIPELINE - MODEL TRAINING
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

RESPONSABILIT√â : Entra√Æner un mod√®le XGBoost pour classification TA
- Charger le dataset CSV
- Split Train/Test (80/20)
- Entra√Æner XGBoost Classifier
- √âvaluer : Accuracy, Precision, Recall, F1, ROC-AUC, Confusion Matrix
- Sauvegarder le mod√®le
- Feature importance analysis

MODEL : XGBoost Classifier
TASK : Classification multiclasse (5 cat√©gories)
CLASSES : NORMAL (0) ‚Üí ELEVATED (1) ‚Üí STAGE_1 (2) ‚Üí STAGE_2 (3) ‚Üí CRISIS (4)
"""

import json
import logging
import pickle
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from colorlog import ColoredFormatter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report,
    roc_curve, auc
)
import xgboost as xgb
from xgboost import XGBClassifier


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# LOGGING SETUP
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def setup_logging():
    """Configure le logging avec couleurs"""
    formatter = ColoredFormatter(
        log_colors={
            'DEBUG': 'cyan',
            'INFO': 'green',
            'WARNING': 'yellow',
            'ERROR': 'red',
            'CRITICAL': 'red,bg_white',
        },
        fmt='%(log_color)s[%(asctime)s %(levelname)s]%(reset)s %(message)s',
        datefmt='%H:%M:%S'
    )
    handler = logging.StreamHandler()
    handler.setFormatter(formatter)
    logger = logging.getLogger(__name__)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)
    return logger

logger = setup_logging()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MODEL TRAINER CLASS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class MLModelTrainer:
    """
    Entra√Æne et √©value un mod√®le XGBoost pour la classification TA
    """
    
    # Noms des classes pour affichage
    CLASS_NAMES = {
        0: 'NORMAL',
        1: 'ELEVATED',
        2: 'HYPERTENSION_STAGE_1',
        3: 'HYPERTENSION_STAGE_2',
        4: 'HYPERTENSIVE_CRISIS'
    }
    
    # Features utilis√©es pour l'entra√Ænement
    FEATURE_COLUMNS = [
        'systolic',
        'diastolic',
        'age',
        'gender',
        'trend',
        'risk_score',
        'hour_of_day'
    ]
    
    # Target
    TARGET_COLUMN = 'blood_pressure_category'
    
    def __init__(self, model_dir: str = 'ml_models'):
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(exist_ok=True)
        
        self.model = None
        self.scaler = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.X_train_scaled = None
        self.X_test_scaled = None
        
        self.metrics = {}
    
    def load_dataset(self, csv_file: str) -> pd.DataFrame:
        """
        Charge le dataset CSV
        
        Args:
            csv_file: Chemin du fichier CSV
            
        Returns:
            DataFrame
        """
        logger.info("=" * 70)
        logger.info("CHARGEMENT DU DATASET")
        logger.info("=" * 70)
        
        logger.info(f"üìñ Chargement {csv_file}...")
        df = pd.read_csv(csv_file)
        logger.info(f"‚úÖ Dataset charg√©: {len(df)} lignes x {len(df.columns)} colonnes")
        
        # V√©rifier les colonnes requises
        missing_cols = set(self.FEATURE_COLUMNS + [self.TARGET_COLUMN]) - set(df.columns)
        if missing_cols:
            raise ValueError(f"Colonnes manquantes: {missing_cols}")
        
        logger.info(f"‚úÖ Toutes les colonnes requises pr√©sentes")
        return df
    
    def prepare_data(self, df: pd.DataFrame, test_size: float = 0.2, random_state: int = 42):
        """
        Pr√©pare les donn√©es : split train/test + scaling
        
        Args:
            df: DataFrame complet
            test_size: Pourcentage test
            random_state: Seed pour reproductibilit√©
        """
        logger.info("=" * 70)
        logger.info("PR√âPARATION DES DONN√âES")
        logger.info("=" * 70)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 1. FEATURES & TARGET
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        X = df[self.FEATURE_COLUMNS].copy()
        y = df[self.TARGET_COLUMN].copy()
        
        logger.info(f"üìä Features shape: {X.shape}")
        logger.info(f"üè∑Ô∏è  Target shape: {y.shape}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 2. TRAIN/TEST SPLIT
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y,
            test_size=test_size,
            random_state=random_state,
            stratify=y  # Important pour les datasets d√©s√©quilibr√©s
        )
        
        logger.info(f"‚úÖ Train size: {len(self.X_train)} ({len(self.X_train)/len(X)*100:.1f}%)")
        logger.info(f"‚úÖ Test size: {len(self.X_test)} ({len(self.X_test)/len(X)*100:.1f}%)")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 3. SCALING (IMPORTANT pour XGBoost avec certains hyperparams)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        self.scaler = StandardScaler()
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)
        
        logger.info("‚úÖ Scaling compl√©t√©")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 4. DISTRIBUTION DES CLASSES
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.info("üè∑Ô∏è  Distribution des classes (train):")
        for class_id, count in self.y_train.value_counts().sort_index().items():
            class_name = self.CLASS_NAMES[class_id]
            pct = count / len(self.y_train) * 100
            logger.info(f"   {class_name:25s}: {count:5d} ({pct:5.1f}%)")
    
    def train_model(self, n_estimators: int = 200, max_depth: int = 7, learning_rate: float = 0.1):
        """
        Entra√Æne le mod√®le XGBoost
        
        Args:
            n_estimators: Nombre d'arbres
            max_depth: Profondeur max des arbres
            learning_rate: Taux d'apprentissage
        """
        logger.info("=" * 70)
        logger.info("ENTRA√éNEMENT DU MOD√àLE XGBOOST")
        logger.info("=" * 70)
        
        logger.info(f"‚öôÔ∏è  Hyperparam√®tres:")
        logger.info(f"   n_estimators: {n_estimators}")
        logger.info(f"   max_depth: {max_depth}")
        logger.info(f"   learning_rate: {learning_rate}")
        
        # Cr√©er et entra√Æner le mod√®le
        self.model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            learning_rate=learning_rate,
            objective='multi:softmax',  # Classification multiclasse
            num_class=5,  # 5 cat√©gories
            random_state=42,
            verbosity=1,
            eval_metric='mlogloss',
            tree_method='hist'  # Fast GPU training if available
        )
        
        logger.info("üöÄ Entra√Ænement en cours...")
        self.model.fit(
            self.X_train_scaled,
            self.y_train,
            eval_set=[(self.X_test_scaled, self.y_test)],
            verbose=False
        )
        
        logger.info("‚úÖ Entra√Ænement compl√©t√©!")
    
    def evaluate_model(self) -> Dict:
        """
        √âvalue le mod√®le sur le test set
        
        Returns:
            Dictionnaire avec les m√©triques
        """
        logger.info("=" * 70)
        logger.info("√âVALUATION DU MOD√àLE")
        logger.info("=" * 70)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 1. PREDICTIONS
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        y_pred = self.model.predict(self.X_test_scaled)
        y_pred_proba = self.model.predict_proba(self.X_test_scaled)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 2. M√âTRIQUES GLOBALES
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        accuracy = accuracy_score(self.y_test, y_pred)
        precision_macro = precision_score(self.y_test, y_pred, average='macro', zero_division=0)
        recall_macro = recall_score(self.y_test, y_pred, average='macro', zero_division=0)
        f1_macro = f1_score(self.y_test, y_pred, average='macro', zero_division=0)
        
        logger.info("üìä M√©triques globales:")
        logger.info(f"   Accuracy  : {accuracy:.4f}")
        logger.info(f"   Precision : {precision_macro:.4f}")
        logger.info(f"   Recall    : {recall_macro:.4f}")
        logger.info(f"   F1-Score  : {f1_macro:.4f}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 3. RAPPORT D√âTAILL√â PAR CLASSE
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.info("\nüìã Rapport d√©taill√© par classe:")
        logger.info("-" * 70)
        report = classification_report(
            self.y_test, y_pred,
            target_names=[self.CLASS_NAMES[i] for i in range(5)],
            digits=4
        )
        logger.info(report)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 4. CONFUSION MATRIX
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        cm = confusion_matrix(self.y_test, y_pred)
        logger.info("üìä Matrice de confusion:")
        logger.info("-" * 70)
        
        # Format la matrice
        header = "Predicted ‚Üí"
        logger.info(f"     {header:60s}")
        for i, class_id in enumerate(range(5)):
            class_name = self.CLASS_NAMES[class_id][:15]
            row_str = f"{class_name:15s} | " + " ".join(f"{cm[i, j]:6d}" for j in range(5))
            logger.info(row_str)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 5. ROC-AUC (ONE-VS-REST)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        try:
            # Binariser les labels pour ROC-AUC multi-classe
            from sklearn.preprocessing import label_binarize
            y_test_bin = label_binarize(self.y_test, classes=range(5))
            
            roc_auc_scores = []
            for i in range(5):
                try:
                    roc_auc = roc_auc_score(y_test_bin[:, i], y_pred_proba[:, i])
                    roc_auc_scores.append(roc_auc)
                    logger.info(f"   ROC-AUC {self.CLASS_NAMES[i]:25s}: {roc_auc:.4f}")
                except:
                    logger.warning(f"   ROC-AUC {self.CLASS_NAMES[i]:25s}: N/A")
            
            roc_auc_macro = np.mean([s for s in roc_auc_scores if not np.isnan(s)])
            logger.info(f"   ROC-AUC (macro)                  : {roc_auc_macro:.4f}")
        except Exception as e:
            logger.warning(f"Erreur calcul ROC-AUC: {e}")
            roc_auc_macro = None
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 6. FEATURE IMPORTANCE
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.info("\nüîç Feature Importance (top 5):")
        logger.info("-" * 70)
        
        feature_importance = self.model.feature_importances_
        sorted_idx = np.argsort(feature_importance)[::-1]
        
        for rank, idx in enumerate(sorted_idx[:5], 1):
            feature_name = self.FEATURE_COLUMNS[idx]
            importance = feature_importance[idx]
            bar = "‚ñà" * int(importance * 50)
            logger.info(f"   {rank}. {feature_name:20s}: {importance:.4f} {bar}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 7. RETOUR DES M√âTRIQUES
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        self.metrics = {
            'accuracy': accuracy,
            'precision': precision_macro,
            'recall': recall_macro,
            'f1': f1_macro,
            'roc_auc': roc_auc_macro if roc_auc_macro else accuracy,
            'confusion_matrix': cm.tolist(),
            'feature_importance': dict(zip(self.FEATURE_COLUMNS, feature_importance))
        }
        
        return self.metrics
    
    def save_model(self, name: str = 'blood_pressure_classifier'):
        """
        Sauvegarde le mod√®le et les m√©tadonn√©es
        
        Args:
            name: Nom du mod√®le
        """
        logger.info("=" * 70)
        logger.info("SAUVEGARDE DU MOD√àLE")
        logger.info("=" * 70)
        
        # Chemin des fichiers
        model_file = self.model_dir / f'{name}.pkl'
        scaler_file = self.model_dir / f'{name}_scaler.pkl'
        metadata_file = self.model_dir / f'{name}_metadata.json'
        
        # Sauvegarder le mod√®le
        joblib.dump(self.model, model_file)
        logger.info(f"‚úÖ Mod√®le sauvegard√©: {model_file}")
        
        # Sauvegarder le scaler
        joblib.dump(self.scaler, scaler_file)
        logger.info(f"‚úÖ Scaler sauvegard√©: {scaler_file}")
        
        # Sauvegarder les m√©tadonn√©es
        metadata = {
            'model_name': name,
            'model_version': '1.0.0',
            'feature_columns': self.FEATURE_COLUMNS,
            'target_column': self.TARGET_COLUMN,
            'class_names': self.CLASS_NAMES,
            'metrics': self.metrics,
            'hyperparameters': {
                'n_estimators': self.model.n_estimators,
                'max_depth': self.model.max_depth,
                'learning_rate': self.model.learning_rate
            }
        }
        
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2)
        logger.info(f"‚úÖ M√©tadonn√©es sauvegard√©es: {metadata_file}")
        
        logger.info(f"\nüìÅ Tous les fichiers du mod√®le:")
        logger.info(f"   - {model_file}")
        logger.info(f"   - {scaler_file}")
        logger.info(f"   - {metadata_file}")
    
    def run_full_training(self, csv_file: str, model_name: str = 'blood_pressure_classifier'):
        """
        Pipeline complet : Load ‚Üí Prepare ‚Üí Train ‚Üí Evaluate ‚Üí Save
        
        Args:
            csv_file: Chemin du CSV avec features
            model_name: Nom du mod√®le √† sauvegarder
        """
        logger.info("\n" + "=" * 70)
        logger.info("üöÄ D√âMARRAGE DU PIPELINE D'ENTRA√éNEMENT")
        logger.info("=" * 70 + "\n")
        
        # √âtape 1: Charger
        df = self.load_dataset(csv_file)
        
        # √âtape 2: Pr√©parer
        self.prepare_data(df)
        
        # √âtape 3: Entra√Æner
        self.train_model()
        
        # √âtape 4: √âvaluer
        self.evaluate_model()
        
        # √âtape 5: Sauvegarder
        self.save_model(model_name)
        
        logger.info("\n" + "=" * 70)
        logger.info("‚úÖ ENTRA√éNEMENT COMPL√âT√â AVEC SUCC√àS!")
        logger.info("=" * 70)
        logger.info(f"üìä Mod√®le pr√™t: {model_name}")
        logger.info(f"   Accuracy: {self.metrics['accuracy']:.4f}")
        logger.info(f"   F1-Score: {self.metrics['f1']:.4f}")
        logger.info(f"   ROC-AUC : {self.metrics['roc_auc']:.4f}\n")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MAIN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

if __name__ == "__main__":
    import sys
    
    # Chemin du CSV (argument ou default)
    csv_file = sys.argv[1] if len(sys.argv) > 1 else 'ml_data/blood_pressure_features.csv'
    
    # Lancer l'entra√Ænement
    trainer = MLModelTrainer(model_dir='ml_models')
    trainer.run_full_training(csv_file)
